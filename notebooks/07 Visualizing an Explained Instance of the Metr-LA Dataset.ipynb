{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Verbal Explanation of Spatial Temporal GNNs for Traffic Forecasting</h1>\n",
    "    <h2>Visualizing an Explained Instance of the Metr-LA Dataset</h2>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook an explained instance of Metr-LA is visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Loading the Data\n",
    "The data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'metr-la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'adj_mx_metr_la.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix, the node indices and the\n",
    "# matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_locations_dataframe\n",
    "\n",
    "# Get the dataframe containing the latitude and longitude of each sensor.\n",
    "locations_df = get_locations_dataframe(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'graph_sensor_locations_metr_la.csv'),\n",
    "    has_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the node positions dictionary.\n",
    "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get the explained data.\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'y_test.npy'))\n",
    "\n",
    "test_clusters = np.load(os.path.join(BASE_DATA_DIR, 'clustered', 'x_test.npy'))\n",
    "test_translations = np.load(os.path.join(BASE_DATA_DIR, 'translated', 'test.npy'))\n",
    "\n",
    "# Get the time information of the explained data.\n",
    "x_test_time = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_test_time.npy'))\n",
    "y_test_time = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'y_test_time.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance speeds are turned into km/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the results in kilometers per hour.\n",
    "from src.utils.config import MPH_TO_KMH_FACTOR\n",
    "\n",
    "\n",
    "x_test[..., 0] = x_test[..., 0] * MPH_TO_KMH_FACTOR\n",
    "y_test = y_test * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Visualization\n",
    "The first instance explanation is visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "sample_x = x_test[i]\n",
    "clusters_x = test_clusters[i]\n",
    "sample_y = y_test[i]\n",
    "sample_x_time = x_test_time[i]\n",
    "sample_y_time = y_test_time[i]\n",
    "\n",
    "clusters_x = clusters_x.astype(object)\n",
    "\n",
    "verbal_translation = test_translations[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_timesteps, n_nodes, _ = y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.unique(clusters_x):\n",
    "    if c == -1:\n",
    "        clusters_x[clusters_x == c] = ' '\n",
    "    else:\n",
    "        clusters_x[clusters_x == c] = f'cluster {c}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_y = (sample_y > 0).astype(np.int64).astype(object)\n",
    "clusters_y[clusters_y == 0] = ' '\n",
    "clusters_y[clusters_y == 1] = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.analyisis import get_node_values_with_clusters_and_location_dataframe\n",
    "\n",
    "df = get_node_values_with_clusters_and_location_dataframe(sample_x[..., 0:1], clusters_x, node_pos_dict, locations_df, sample_x_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons = {\n",
    "    ' ': '',\n",
    "    'cluster 0': 'star',\n",
    "    'cluster 1': 'circle',\n",
    "    'cluster 2':'heart',\n",
    "    'cluster 3': 'play',\n",
    "    'cluster 4': 'pause',\n",
    "    'target': 'certified'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['icon'] = df['cluster'].apply(lambda x: icons[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San diego freeway at kms 11, 12, 13 and 14 was forecasted to see severe congestion on Wednesday, 04/06/2012, with an average speed of 24.04 km/h from 07:45 to 08:40. This occurred because of a series of congestions and a free flow.\n",
      "\n",
      "To start, a contributing free flow materialized, at 107.75 km/h, on San Diego Freeway at kms 8 and 10 from 06:45 to 06:50.\n",
      "\n",
      "Following this, a contributing congestion occurred, averaging at a speed of 82.83 km/h, on, another time, San Diego Freeway at kms 9 and 10 from 06:45 to 07:10.\n",
      "\n",
      "Afterwards, a new contributing congestion took place, with an average speed of 88.65 km/h, on Ventura Freeway at kms 27, 28, 29, 30 and 31 occurring from 06:45 to 07:40. The congestion also took place on, once again, San Diego Freeway at kms 11, 12 and 13.\n",
      "\n",
      "After this, a contributing severe congestion happened on, yet again, San Diego Freeway at kms 10, 11, 12, 13, 14 and 15 from 06:45 to 07:40 with an average speed of 19.70 km/h.\n",
      "\n",
      "To conclude, yet a further contributing congestion occurred at 07:30 on, again, Ventura Freeway at km 27 with an average speed of 72.62 km/h.\n"
     ]
    }
   ],
   "source": [
    "print(verbal_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d7139b53954d37b1a28df49bc18714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': ['data'], 'id': '6w1zy4', 'na…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "show_kepler_map(\n",
    "    df, config_file_path='../config/kepler/metr-la/visualization_test_x_clusters.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.analyisis import (\n",
    "    get_node_values_with_clusters_and_location_dataframe)\n",
    "\n",
    "df = get_node_values_with_clusters_and_location_dataframe(sample_y, clusters_y, node_pos_dict, locations_df, sample_y_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['icon'] = df['cluster'].apply(lambda x: icons[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b98b1ef8f454bb894ac785a3b76d12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': ['data'], 'id': 'lbbs8b4ts', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "show_kepler_map(\n",
    "    df, config_file_path='../config/kepler/metr-la/visualization_test_y_clusters.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
