{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected device is: \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device for training and querying the model.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The selected device is: \"{DEVICE}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'metr-la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialTemporalGNN(\n",
       "  (encoder): Linear(in_features=9, out_features=64, bias=False)\n",
       "  (s_gnns): ModuleList(\n",
       "    (0-11): 12 x S_GNN(\n",
       "      (latent_encoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (1): Linear(in_features=64, out_features=32, bias=False)\n",
       "      )\n",
       "      (linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (hidden_s_gnns): ModuleList(\n",
       "    (0-10): 11 x S_GNN(\n",
       "      (latent_encoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (1): Linear(in_features=64, out_features=32, bias=False)\n",
       "      )\n",
       "      (linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (grus): ModuleList(\n",
       "    (0-11): 12 x GRU(\n",
       "      (z_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (z_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (r_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (r_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (h_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (h_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (positional_encoder): PositionalEncoder()\n",
       "  (transformer): Transformer(\n",
       "    (queries_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (keys_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (values_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (normalization): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (normalization_out): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'adj_mx_metr_la.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix and the matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
    "\n",
    "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
    "\n",
    "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                      'st_gnn_metr_la.pth')\n",
    "\n",
    "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
    "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
    "\n",
    "spatial_temporal_gnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_locations_dataframe\n",
    "\n",
    "# Get the dataframe containing the latitude and longitude of each sensor.\n",
    "locations_df = get_locations_dataframe(\n",
    "    os.path.join(BASE_DATA_DIR, 'graph_sensor_locations_metr_la.csv'),\n",
    "    has_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids_dict\n",
    "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.spatial_temporal_gnn.prediction import predict\n",
    "\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_train.npy'))\n",
    "y_train = predict(spatial_temporal_gnn, x_train, scaler, DEVICE)\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_val.npy'))\n",
    "y_val = predict(spatial_temporal_gnn, x_val, scaler, DEVICE)\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_test.npy'))\n",
    "y_test = predict(spatial_temporal_gnn, x_test, scaler, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPH_TO_KMH_FACTOR = 1.609344\n",
    "y_train = y_train * MPH_TO_KMH_FACTOR\n",
    "y_val = y_val * MPH_TO_KMH_FACTOR\n",
    "y_test = y_test * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_timesteps, n_nodes, _ = y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sensor_id  latitude  longitude\n",
       "index                               \n",
       "0        773869  34.15497 -118.31829\n",
       "1        767541  34.11621 -118.23799\n",
       "2        767542  34.11641 -118.23819\n",
       "3        717447  34.07248 -118.26772\n",
       "4        717446  34.07142 -118.26572"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def get_clusters(\n",
    "    instance: np.ndarray, eps: float, min_samples: int,\n",
    "    speed_distance_weight: float = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the clusters of the given instance using the DBSCAN algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance to cluster.\n",
    "    adj_distance_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph measured in distance\n",
    "        between 0 and 1.\n",
    "    time_distance_matrix : ndarray\n",
    "        The matrix measuring the distance between the time steps\n",
    "        of the nodes in the graph between 0 and 1.\n",
    "    eps : float\n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other.\n",
    "    min_samples : int\n",
    "        The number of samples in a neighborhood for a point for it to be\n",
    "        considered as a core point.\n",
    "    speed_distance_weight : float, optional\n",
    "        The weight of the speed distance in the clustering process,\n",
    "        by default 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        The clusters of the given instance.\n",
    "    \"\"\"\n",
    "    n_timesteps, n_nodes, _ = instance.shape\n",
    "\n",
    "    # Add the time dimension to the instance.\n",
    "    #instance = np.expand_dims(instance, axis=-1)\n",
    "   \n",
    "    # Add a feature to the last dimension of the instance\n",
    "    #print(instance.shape, np.zeros((n_timesteps, n_nodes, 3)).shape)\n",
    "    instance = instance.copy()\n",
    "    \n",
    "    instance = np.concatenate((instance, np.zeros((n_timesteps, n_nodes, 3))),\n",
    "                              axis=-1)\n",
    "    \n",
    "    for i in range(n_timesteps):\n",
    "        instance[i, :, -3] = i\n",
    "\n",
    "    for n in range(n_nodes):\n",
    "        row = locations_df.iloc[n]\n",
    "        latitude = row.latitude\n",
    "        longitude = row.longitude\n",
    "        instance[:, n, -2] = latitude\n",
    "        instance[:, n, -1] = longitude\n",
    "\n",
    "    for i in range(instance.shape[-1]):\n",
    "        min = np.min(instance[..., i])\n",
    "        max = np.max(instance[..., i])\n",
    "        # Apply min-max normalization to the instance.\n",
    "        instance[..., i] = (instance[..., i] - min) / (max - min)\n",
    "\n",
    "    # Apply weight factor scaling to the speed feature.\n",
    "    instance[..., 0] = instance[..., 0] * speed_distance_weight\n",
    "    \n",
    "    instance = instance.reshape(-2, instance.shape[-1])\n",
    "\n",
    "    # Compute the clusters of the given instance using the DBSCAN algorithm.\n",
    "    dbscan = DBSCAN(metric='euclidean', eps=eps, min_samples=min_samples,\n",
    "                    n_jobs=-1)\n",
    "    clusters = dbscan.fit_predict(instance)\n",
    "\n",
    "    # Add a dummy dimension to the clusters array.\n",
    "    clusters = np.expand_dims(clusters, axis=1)\n",
    "\n",
    "    # Reshape the clusters array to have the same shape as the instance.\n",
    "    clusters = clusters.reshape(n_timesteps, n_nodes, 1)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_clusters(\n",
    "    instance: np.ndarray, n_clusters: int,\n",
    "    speed_distance_weight: float = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the clusters of the given instance using the DBSCAN algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance to cluster.\n",
    "    adj_distance_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph measured in distance\n",
    "        between 0 and 1.\n",
    "    time_distance_matrix : ndarray\n",
    "        The matrix measuring the distance between the time steps\n",
    "        of the nodes in the graph between 0 and 1.\n",
    "    eps : float\n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other.\n",
    "    min_samples : int\n",
    "        The number of samples in a neighborhood for a point for it to be\n",
    "        considered as a core point.\n",
    "    speed_distance_weight : float, optional\n",
    "        The weight of the speed distance in the clustering process,\n",
    "        by default 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        The clusters of the given instance.\n",
    "    \"\"\"\n",
    "    n_timesteps, n_nodes, _ = instance.shape\n",
    "\n",
    "    # Add the time dimension to the instance.\n",
    "    #instance = np.expand_dims(instance, axis=-1)\n",
    "   \n",
    "    # Add a feature to the last dimension of the instance\n",
    "    #print(instance.shape, np.zeros((n_timesteps, n_nodes, 3)).shape)\n",
    "    instance = instance.copy()\n",
    "    \n",
    "    instance = np.concatenate((instance, np.zeros((n_timesteps, n_nodes, 3))),\n",
    "                              axis=-1)\n",
    "    \n",
    "    for i in range(n_timesteps):\n",
    "        instance[i, :, -3] = i\n",
    "\n",
    "    for n in range(n_nodes):\n",
    "        row = locations_df.iloc[n]\n",
    "        latitude = row.latitude\n",
    "        longitude = row.longitude\n",
    "        instance[:, n, -2] = latitude\n",
    "        instance[:, n, -1] = longitude\n",
    "\n",
    "    for i in range(instance.shape[-1]):\n",
    "        min = np.min(instance[..., i])\n",
    "        max = np.max(instance[..., i])\n",
    "        # Apply min-max normalization to the instance.\n",
    "        instance[..., i] = (instance[..., i] - min) / (max - min)\n",
    "\n",
    "    # Apply weight factor scaling to the speed feature.\n",
    "    instance[..., 0] = instance[..., 0] * speed_distance_weight\n",
    "    \n",
    "    instance = instance.reshape(-2, instance.shape[-1])\n",
    "\n",
    "    # Compute the clusters of the given instance using the DBSCAN algorithm.\n",
    "    dbscan = KMeans(n_clusters=n_clusters, random_state=SEED)\n",
    "    clusters = dbscan.fit_predict(instance)\n",
    "\n",
    "    # Add a dummy dimension to the clusters array.\n",
    "    clusters = np.expand_dims(clusters, axis=1)\n",
    "\n",
    "    # Reshape the clusters array to have the same shape as the instance.\n",
    "    clusters = clusters.reshape(n_timesteps, n_nodes, 1)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_within_clusters_variance(\n",
    "    instance: np.ndarray, clusters: np.ndarray) -> float:\n",
    "    \"\"\"Get the Within-Cluster Variance metric of the clusters\n",
    "    obtained on the given instance in terms of speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance on which the clusters\n",
    "        are evaluated.\n",
    "    clusters : ndarray\n",
    "        The clusters obtained on the given instance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Within-Cluster Variance metric result.\n",
    "    \"\"\"\n",
    "    # Set the intial value of the numerator sum to 0.\n",
    "    numerator_sum = 0.\n",
    "    # Set the initial value of the total number of nodes to 0.\n",
    "    total_node_number = 0.\n",
    "\n",
    "    for c in np.unique(clusters):\n",
    "        # Get the sub-sample of the nodes in the graph that belong to the\n",
    "        # current cluster.\n",
    "        sub_sample = instance[clusters == c]\n",
    "        # Get the length of the sub-sample.\n",
    "        len_sub_sample = len(sub_sample)\n",
    "        # Update the total nominator sum.\n",
    "        numerator_sum += np.var(sub_sample) * len_sub_sample\n",
    "        # Update the total number of nodes with the length of the sub-sample.\n",
    "        total_node_number += len_sub_sample\n",
    "\n",
    "    return numerator_sum / (total_node_number * np.var(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def are_clusters_connected(\n",
    "    clusters: np.ndarray, cluster_1: int, cluster_2: int,\n",
    "    adj_matrix: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether the given clusters are connected or not, by\n",
    "    observing whethere there are node spatially or temporally\n",
    "    connected between the two clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clusters : ndarray\n",
    "        The clustered instance.\n",
    "    cluster_1 : int\n",
    "        The ID of the first cluster.\n",
    "    cluster_2 : int\n",
    "        The ID of the second cluster.\n",
    "    adj_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Whether the given clusters are connected or not.\n",
    "    \"\"\"\n",
    "    # Get the indices of the nodes that belong to the two clusters.\n",
    "    # indices = (list of timesteps, list of nodes).\n",
    "    indices_cluster_1 = np.where(clusters == cluster_1)[:-1]\n",
    "    indices_cluster_2 = np.where(clusters == cluster_2)[:-1]\n",
    "\n",
    "    # Zip the indices of the nodes that belong to the two clusters.\n",
    "    zip_indices_cluster_1 = zip(indices_cluster_1[0], indices_cluster_1[1])\n",
    "    zip_indices_cluster_2 = zip(indices_cluster_2[0], indices_cluster_2[1])\n",
    "\n",
    "    for indices_cluster_1 in zip_indices_cluster_1:\n",
    "        for indices_cluster_2 in zip_indices_cluster_2:\n",
    "            # Get the indices of the timestep and the nodes.\n",
    "            timestep_0, node_0 = indices_cluster_1\n",
    "            timestep_1, node_1 = indices_cluster_2\n",
    "            # Check if the nodes are spatially connected in the same timestep.\n",
    "            if timestep_0 == timestep_1 and (adj_matrix[node_0, node_1] > 0 or adj_matrix[node_1, node_0] > 0):\n",
    "                return True\n",
    "            # Check if the nodes are the same and temporally connected.\n",
    "            if node_0 == node_1 and np.abs(timestep_0 - timestep_1) == 1:\n",
    "                return True\n",
    "    # If no connection is found, return False.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(adj_matrix-adj_matrix.T) < 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174379"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.abs(1 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_connected_cluster_dissimilarity(\n",
    "    instance: np.ndarray, clusters: np.ndarray,\n",
    "    adj_matrix: np.ndarray) -> float:\n",
    "    \"\"\"Get the Connected Cluster Dissimilarity metric of the clusters\n",
    "    obtained on the given instance in terms of speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance on which the clusters\n",
    "        are evaluated.\n",
    "    clusters : ndarray\n",
    "        The clusters obtained on the given instance.\n",
    "    adj_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Connected Cluster Dissimilarity metric result.\n",
    "    \"\"\"\n",
    "    # Get the total unique cluster IDs.\n",
    "    total_clusters = np.unique(clusters) #[c for c in np.unique(clusters) if c != -1]\n",
    "\n",
    "    # Set the initial value of the denominator sum to 0.\n",
    "    denominator_sum = 0.\n",
    "    # Set the initial value of the nominator sum to 0.\n",
    "    nominator_sum = 0.\n",
    "\n",
    "    for i, c1 in enumerate(total_clusters):\n",
    "        for c2 in total_clusters[i+1:]:\n",
    "            # If the two clusters are not connected, continue the loop.\n",
    "            #if not are_clusters_connected(clusters, c1, c2, adj_matrix):\n",
    "            #    continue\n",
    "            # Get the sub-samples of the nodes in the graph that belong to the\n",
    "            # current clusters.\n",
    "            sub_sample1 = instance[clusters == c1]\n",
    "            sub_sample2 = instance[clusters == c2]\n",
    "            # Get the length of the sub-samples.\n",
    "            len_sub_sample1 = len(sub_sample1)\n",
    "            len_sub_sample2 = len(sub_sample2)\n",
    "            # Compute the square root of the product of the lengths.\n",
    "            sqrt_lens = np.sqrt(len_sub_sample1 * len_sub_sample2)\n",
    "            # Compute the absolute difference between the means.\n",
    "            abs_mean_diff = np.abs(np.mean(sub_sample1) - np.mean(sub_sample2))\n",
    "            # Update the nominator sum.\n",
    "            nominator_sum += sqrt_lens * abs_mean_diff\n",
    "            # Update the denominator sum.\n",
    "            denominator_sum += sqrt_lens\n",
    "\n",
    "    return nominator_sum / denominator_sum if denominator_sum > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = y_test[100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[105.516815]\n",
      "  [106.30835 ]\n",
      "  [110.63477 ]\n",
      "  ...\n",
      "  [ 96.66321 ]\n",
      "  [105.756   ]\n",
      "  [ 94.39404 ]]\n",
      "\n",
      " [[105.64159 ]\n",
      "  [106.30521 ]\n",
      "  [110.73598 ]\n",
      "  ...\n",
      "  [ 96.28707 ]\n",
      "  [105.96441 ]\n",
      "  [ 94.436615]]\n",
      "\n",
      " [[105.365875]\n",
      "  [106.34077 ]\n",
      "  [110.47715 ]\n",
      "  ...\n",
      "  [ 95.90711 ]\n",
      "  [105.84915 ]\n",
      "  [ 92.498146]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[105.95852 ]\n",
      "  [106.31506 ]\n",
      "  [111.67196 ]\n",
      "  ...\n",
      "  [ 96.07069 ]\n",
      "  [105.978714]\n",
      "  [ 77.985504]]\n",
      "\n",
      " [[106.1215  ]\n",
      "  [106.41055 ]\n",
      "  [111.718094]\n",
      "  ...\n",
      "  [ 95.82342 ]\n",
      "  [106.1726  ]\n",
      "  [ 83.10759 ]]\n",
      "\n",
      " [[106.14085 ]\n",
      "  [106.37718 ]\n",
      "  [111.34969 ]\n",
      "  ...\n",
      "  [ 95.77394 ]\n",
      "  [106.050285]\n",
      "  [ 82.92526 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-Cluster Variance: 0.08989691605257641\n",
      "Connected Cluster Dissimilarity: 19.197927576314953\n"
     ]
    }
   ],
   "source": [
    "sample = y_test[100]\n",
    "\n",
    " \n",
    "clusters = get_clusters(sample, n_clusters=9)\n",
    "\n",
    "print('Within-Cluster Variance:', get_within_clusters_variance(sample, clusters))\n",
    "print('Connected Cluster Dissimilarity:', get_connected_cluster_dissimilarity(sample, clusters, adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "parameter_grid = ParameterGrid({\n",
    "    'eps': [.2],#[.1, .2, .3, .4],\n",
    "    'min_samples': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = ParameterGrid({\n",
    "    'n_clusters': [n for n in range(4, 15)]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 4\n",
      "\tWithin-Cluster Variance: 0.242 Connected Cluster Dissimilarity: 18.2\n",
      "\n",
      "n_clusters: 5\n",
      "\tWithin-Cluster Variance: 0.168 Connected Cluster Dissimilarity: 18.5\n",
      "\n",
      "n_clusters: 6\n",
      "\tWithin-Cluster Variance: 0.157 Connected Cluster Dissimilarity: 17.9\n",
      "\n",
      "n_clusters: 7\n",
      "\tWithin-Cluster Variance: 0.139 Connected Cluster Dissimilarity: 17.8\n",
      "\n",
      "n_clusters: 8\n",
      "\tWithin-Cluster Variance: 0.127 Connected Cluster Dissimilarity: 17.5\n",
      "\n",
      "n_clusters: 9\n",
      "\tWithin-Cluster Variance: 0.116 Connected Cluster Dissimilarity: 17.4\n",
      "\n",
      "n_clusters: 10\n",
      "\tWithin-Cluster Variance: 0.108 Connected Cluster Dissimilarity: 17.4\n",
      "\n",
      "n_clusters: 11\n",
      "\tWithin-Cluster Variance: 0.102 Connected Cluster Dissimilarity: 17.3\n",
      "\n",
      "n_clusters: 12\n",
      "\tWithin-Cluster Variance: 0.096 Connected Cluster Dissimilarity: 17.3\n",
      "\n",
      "n_clusters: 13\n",
      "\tWithin-Cluster Variance: 0.0914 Connected Cluster Dissimilarity: 17.2\n",
      "\n",
      "n_clusters: 14\n",
      "\tWithin-Cluster Variance: 0.087 Connected Cluster Dissimilarity: 17.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm\n",
    "\n",
    "for p in parameter_grid:\n",
    "    total_within_cluster_variance = 0.\n",
    "    total_connected_cluster_dissimilarity = 0.\n",
    "    print('n_clusters:', p['n_clusters'])\n",
    "    for instance in y_train[:500]:\n",
    "        clusters = get_clusters(instance, n_clusters=p['n_clusters'])\n",
    "        within_cluster_variance = get_within_clusters_variance(\n",
    "            instance, clusters)\n",
    "        connected_cluster_dissimilarity = get_connected_cluster_dissimilarity(\n",
    "            instance, clusters, adj_matrix)\n",
    "        total_within_cluster_variance += within_cluster_variance\n",
    "        total_connected_cluster_dissimilarity += connected_cluster_dissimilarity\n",
    "\n",
    "    avg_within_cluster_variance = total_within_cluster_variance / len(y_train[:500])\n",
    "    avg_connected_cluster_dissimilarity = total_connected_cluster_dissimilarity / len(y_train[:500])\n",
    "    print('\\tWithin-Cluster Variance:', f'{avg_within_cluster_variance:.3g}', \n",
    "          'Connected Cluster Dissimilarity:', f'{avg_connected_cluster_dissimilarity:.3g}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = .2\n",
    "MIN_SAMPLES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation with eps: 0.2 min_samples: 7\n",
      "\tWithin-Cluster Variance: 0.0313 Connected Cluster Dissimilarity: 5.01\n"
     ]
    }
   ],
   "source": [
    "total_within_cluster_variance = 0.\n",
    "total_connected_cluster_dissimilarity = 0.\n",
    "print('Test set evaluation with eps:', EPS, 'min_samples:', MIN_SAMPLES)\n",
    "for instance in y_test:\n",
    "    clusters = get_clusters(instance, 9)\n",
    "    within_cluster_variance = get_within_clusters_variance(instance, clusters)\n",
    "    connected_cluster_dissimilarity = get_connected_cluster_dissimilarity(\n",
    "        instance, clusters, adj_matrix)\n",
    "    total_within_cluster_variance += within_cluster_variance\n",
    "    total_connected_cluster_dissimilarity += connected_cluster_dissimilarity\n",
    "\n",
    "avg_within_cluster_variance = total_within_cluster_variance / len(y_train)\n",
    "avg_connected_cluster_dissimilarity = total_connected_cluster_dissimilarity / len(y_train)\n",
    "print('\\tWithin-Cluster Variance:', f'{avg_within_cluster_variance:.3g}', \n",
    "        'Connected Cluster Dissimilarity:', f'{avg_connected_cluster_dissimilarity:.3g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = y_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1017657736308171\n",
      "11.602922802811747\n"
     ]
    }
   ],
   "source": [
    "clusters = get_clusters(instance, 30)\n",
    "\n",
    "print(get_within_clusters_variance(instance, clusters))\n",
    "print(get_connected_cluster_dissimilarity(instance, clusters, adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(clusters.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 30\n"
     ]
    }
   ],
   "source": [
    "print('Number of clusters found:', len(np.unique(clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.concatenate((sample, clusters), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[105.51681519,   0.        ],\n",
       "        [106.30834961,   4.        ],\n",
       "        [110.63477325,   4.        ],\n",
       "        ...,\n",
       "        [ 96.66320801,  15.        ],\n",
       "        [105.7559967 ,   0.        ],\n",
       "        [ 94.39404297,  13.        ]],\n",
       "\n",
       "       [[105.6415863 ,   0.        ],\n",
       "        [106.3052063 ,  13.        ],\n",
       "        [110.73597717,   4.        ],\n",
       "        ...,\n",
       "        [ 96.28707123,  15.        ],\n",
       "        [105.96440887,   0.        ],\n",
       "        [ 94.43661499,  13.        ]],\n",
       "\n",
       "       [[105.36587524,   0.        ],\n",
       "        [106.34076691,  13.        ],\n",
       "        [110.47714996,   4.        ],\n",
       "        ...,\n",
       "        [ 95.90711212,  15.        ],\n",
       "        [105.84915161,   0.        ],\n",
       "        [ 92.49814606,  13.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[105.95851898,  24.        ],\n",
       "        [106.31506348,  11.        ],\n",
       "        [111.67195892,   2.        ],\n",
       "        ...,\n",
       "        [ 96.07068634,  18.        ],\n",
       "        [105.97871399,  24.        ],\n",
       "        [ 77.98550415,  19.        ]],\n",
       "\n",
       "       [[106.12149811,  24.        ],\n",
       "        [106.41055298,  11.        ],\n",
       "        [111.71809387,   2.        ],\n",
       "        ...,\n",
       "        [ 95.82341766,  18.        ],\n",
       "        [106.17259979,  24.        ],\n",
       "        [ 83.10758972,  19.        ]],\n",
       "\n",
       "       [[106.14084625,  24.        ],\n",
       "        [106.37718201,  11.        ],\n",
       "        [111.3496933 ,   2.        ],\n",
       "        ...,\n",
       "        [ 95.77394104,  18.        ],\n",
       "        [106.05028534,  24.        ],\n",
       "        [ 82.92526245,  29.        ]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  7, 15, 22, 28,  5, 13, 14, 10, 17, 21, 25, 23,  9, 12,  3,\n",
       "        8, 27,  1,  6, 26, 20, 19, 11,  2, 16, 29, 18, 24])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters.cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>4</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>4</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>7</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>7</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0    773869  34.15497 -118.31829        0  105.516815         0\n",
       "1    767541  34.11621 -118.23799        4  106.308350         0\n",
       "2    767542  34.11641 -118.23819        4  110.634773         0\n",
       "3    717447  34.07248 -118.26772        7   81.586983         0\n",
       "4    717446  34.07142 -118.26572        7   44.713619         0"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41a7091a8b048aeb0b05aa82018f453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_clusters_connected(clusters, c1, c2, adj_matrix):\n",
    "    cluster_nodes_0 = np.where(clusters == c1)[:-1]\n",
    "    cluster_nodes_1 = np.where(clusters == c2)[:-1]\n",
    "\n",
    "    for i in zip(cluster_nodes_0[0], cluster_nodes_0[1], cluster_nodes_1[0], cluster_nodes_1[1]):\n",
    "        # The nodes are spatially connected.\n",
    "        if adj_matrix[i[1], i[3]] > 0:\n",
    "            return True\n",
    "        # The nodes are the same ones and there is a temporal distance of 1.\n",
    "        if i[1] == i[3] and np.abs(i[0] - i[2]) == 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.855244937941013"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_clusters = np.unique(clusters)\n",
    "\n",
    "denominator_sum = 0.\n",
    "nominator_sum = 0.\n",
    "\n",
    "for i, c1 in enumerate(total_clusters):\n",
    "    for cluster_2 in total_clusters[i+1:]:\n",
    "        if not are_clusters_connected(clusters, c1, cluster_2, adj_matrix):\n",
    "            continue\n",
    "        sub_sample1 = sample[clusters == c1]\n",
    "        sub_sample2 = sample[clusters == cluster_2]\n",
    "        len_sub_sample1 = len(sub_sample1)\n",
    "        len_sub_sample2 = len(sub_sample2)\n",
    "        sqrt_lens = np.sqrt(len_sub_sample1 * len_sub_sample2)\n",
    "        nominator_sum += sqrt_lens * np.abs(np.mean(sub_sample1) - np.mean(sub_sample2))\n",
    "        denominator_sum += sqrt_lens\n",
    "\n",
    "nominator_sum / denominator_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 207, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sample_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample_, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,  48,  28,  63,   4,  64,  65,  66,  67,  -1,\n",
       "         5,   6,  50,   7,   8,  14,  68,   9,  10,  69,  25,  51,  70,\n",
       "        61,  71,  72,  27,  11,  73,  12,  13,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  52,  15,  16,  18,  17,  53,  83,  84,  85,\n",
       "        32,  19,  44,  20,  86,  87,  21,  22,  23,  54,  55,  24,  88,\n",
       "        26,  89,  90,  91,  92,  29,  39,  93,  94,  30,  56,  95,  31,\n",
       "        96,  57,  97,  33,  58,  34,  35,  98,  36,  37,  99,  59,  47,\n",
       "        38,  60,  40, 100,  41, 101, 102, 103,  42, 104, 105, 106, 107,\n",
       "       108,  43, 109, 110, 111,  45, 112, 113, 114, 115,  46, 116, 117,\n",
       "        62, 118, 119, 120, 121, 122, 123,  49, 124, 125])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df_with_clusters['cluster'] = location_df_with_clusters['cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>1</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>2</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>3</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>48</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>717592</td>\n",
       "      <td>34.14604</td>\n",
       "      <td>-118.22430</td>\n",
       "      <td>121</td>\n",
       "      <td>100.792572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>717595</td>\n",
       "      <td>34.14163</td>\n",
       "      <td>-118.18290</td>\n",
       "      <td>122</td>\n",
       "      <td>109.369804</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>772168</td>\n",
       "      <td>34.16542</td>\n",
       "      <td>-118.47985</td>\n",
       "      <td>123</td>\n",
       "      <td>95.773941</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>718141</td>\n",
       "      <td>34.15133</td>\n",
       "      <td>-118.37456</td>\n",
       "      <td>19</td>\n",
       "      <td>106.050285</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>769373</td>\n",
       "      <td>34.10262</td>\n",
       "      <td>-118.31747</td>\n",
       "      <td>49</td>\n",
       "      <td>82.925262</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.15497 -118.31829        0  105.516815         0\n",
       "1       767541  34.11621 -118.23799        1  106.308350         0\n",
       "2       767542  34.11641 -118.23819        2  110.634773         0\n",
       "3       717447  34.07248 -118.26772        3   81.586983         0\n",
       "4       717446  34.07142 -118.26572       48   44.713619         0\n",
       "...        ...       ...        ...      ...         ...       ...\n",
       "2479    717592  34.14604 -118.22430      121  100.792572        11\n",
       "2480    717595  34.14163 -118.18290      122  109.369804        11\n",
       "2481    772168  34.16542 -118.47985      123   95.773941        11\n",
       "2482    718141  34.15133 -118.37456       19  106.050285        11\n",
       "2483    769373  34.10262 -118.31747       49   82.925262        11\n",
       "\n",
       "[2484 rows x 6 columns]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f7e838c9ec4c22ab5e809b17fb83b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.expand_dims(np.repeat(np.linspace(0, 1, n_timesteps), n_nodes), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.concatenate([np.repeat(np.linspace(0, 1, n_timesteps), n_nodes)] * n_nodes, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.repeat(adj_matrix, 12).reshape(speed_distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((n_total_nodes, n_total_nodes))\n",
    "\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    for j in range(similarity_matrix.shape[1]):\n",
    "        i_timestep = i // n_nodes\n",
    "        j_timestep = j // n_nodes\n",
    "        \n",
    "        i_id = i % n_nodes\n",
    "        j_id = j % n_nodes\n",
    "        \n",
    "        time_difference = abs(i_timestep - j_timestep)\n",
    "        #speed_difference = np.linalg.norm(sample_reshaped[i] - sample_reshaped[j])\n",
    "        \n",
    "        if (adj_matrix[i_id][j_id] > .5) * (time_difference <= 2):\n",
    "            speed_difference = np.linalg.norm(sample_reshaped[i] - sample_reshaped[j])\n",
    "        else:\n",
    "            speed_difference = float('inf')\n",
    "        \n",
    "        similarity_matrix[i][j] = speed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(similarity_matrix[similarity_matrix != float('inf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix[similarity_matrix == float('inf')] = max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 3.14331055e-03 3.24172974e-02 4.27729034e+00\n",
      " 4.36017609e+00 4.36315918e+00 5.13887024e+00 5.16516113e+00\n",
      " 5.19464874e+00 8.32704544e+01]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(similarity_matrix[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.796418782568813"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(metric='precomputed', eps=10., min_samples=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dbscan.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.expand_dims(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.reshape(n_timesteps, n_nodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 207, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = np.concatenate((sample, clusters), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 207, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sample_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample_, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 13,  5,  6, 37,  7, 41,  8,  9, 10, 42, 43, 11,\n",
       "       44, 12, 14, 15, -1, 16, 45, 46, 17, 18, 47, 19, 20, 21, 48, 49, 50,\n",
       "       22, 23, 24, 25, 51, 52, 26, 27, 28, 29, 30, 53, 54, 31, 32, 38, 55,\n",
       "       33, 56, 57, 34, 58, 40, 35, 36, 59, 60, 39])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df_with_clusters['cluster'] = location_df_with_clusters['cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>1</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>1</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>2</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>3</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>717592</td>\n",
       "      <td>34.14604</td>\n",
       "      <td>-118.22430</td>\n",
       "      <td>0</td>\n",
       "      <td>100.792572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>717595</td>\n",
       "      <td>34.14163</td>\n",
       "      <td>-118.18290</td>\n",
       "      <td>1</td>\n",
       "      <td>109.369804</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>772168</td>\n",
       "      <td>34.16542</td>\n",
       "      <td>-118.47985</td>\n",
       "      <td>39</td>\n",
       "      <td>95.773941</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>718141</td>\n",
       "      <td>34.15133</td>\n",
       "      <td>-118.37456</td>\n",
       "      <td>2</td>\n",
       "      <td>106.050285</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>769373</td>\n",
       "      <td>34.10262</td>\n",
       "      <td>-118.31747</td>\n",
       "      <td>2</td>\n",
       "      <td>82.925262</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.15497 -118.31829        0  105.516815         0\n",
       "1       767541  34.11621 -118.23799        1  106.308350         0\n",
       "2       767542  34.11641 -118.23819        1  110.634773         0\n",
       "3       717447  34.07248 -118.26772        2   81.586983         0\n",
       "4       717446  34.07142 -118.26572        3   44.713619         0\n",
       "...        ...       ...        ...      ...         ...       ...\n",
       "2479    717592  34.14604 -118.22430        0  100.792572        11\n",
       "2480    717595  34.14163 -118.18290        1  109.369804        11\n",
       "2481    772168  34.16542 -118.47985       39   95.773941        11\n",
       "2482    718141  34.15133 -118.37456        2  106.050285        11\n",
       "2483    769373  34.10262 -118.31747        2   82.925262        11\n",
       "\n",
       "[2484 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff6162bb0494db69e2f15a2c9778c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
